{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of phoBert_model_3_csv.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e281dfa3a93c4653b05093d15d465570":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_56786dfc7cc34c3bb5cd4710f95be7c6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_195d00f6be33479185e25d4d31a09347","IPY_MODEL_aee06554a6d54f9587823015e9afb024"]}},"56786dfc7cc34c3bb5cd4710f95be7c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"195d00f6be33479185e25d4d31a09347":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_913712c43e5b4007a375b920c219df66","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":557,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":557,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_86d28ce581e6474e9745d5790cfb7979"}},"aee06554a6d54f9587823015e9afb024":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5d0512bd76b74b27ab6797d7bc6bbdb4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 557/557 [00:03&lt;00:00, 184B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9ca78c0d2b154ac9b569a0fc1002136e"}},"913712c43e5b4007a375b920c219df66":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"86d28ce581e6474e9745d5790cfb7979":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5d0512bd76b74b27ab6797d7bc6bbdb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9ca78c0d2b154ac9b569a0fc1002136e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d3496dc2ecbc432f9759a72f87c672b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_334b8572b7ed466f91924d72754b53c0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0f2daaeb9c4a411aa36ae63e80e283dc","IPY_MODEL_0376b7fa518745b28f84cb2070c6cc04"]}},"334b8572b7ed466f91924d72754b53c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0f2daaeb9c4a411aa36ae63e80e283dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dfbcb35d184b4eea8f5277fddb33b7ea","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":895321,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":895321,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_359601cc6fb8417d9ef10a407e9cea4b"}},"0376b7fa518745b28f84cb2070c6cc04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d76ae51a3b9b468ab3f45d3f6f8857c4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 895k/895k [00:02&lt;00:00, 377kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b7bdfb3745cf4c5999a079baf82b202d"}},"dfbcb35d184b4eea8f5277fddb33b7ea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"359601cc6fb8417d9ef10a407e9cea4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d76ae51a3b9b468ab3f45d3f6f8857c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b7bdfb3745cf4c5999a079baf82b202d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5f92153bdb574cc58aec69972c177d0c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_836ff1babeea4a79af5ca44b0dcbbed0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a8f044f7ef7c4d328b456de016279cf1","IPY_MODEL_0e34927b3ede40d599526d056dd7b5a0"]}},"836ff1babeea4a79af5ca44b0dcbbed0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a8f044f7ef7c4d328b456de016279cf1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4b2d41296399451b863bc1158ad4ea5b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1135173,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1135173,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_df4604606a3e43f489e0bd39af12ce40"}},"0e34927b3ede40d599526d056dd7b5a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c6944bb5e5ab4fdc80b90a47ea831f28","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.14M/1.14M [00:01&lt;00:00, 780kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9f0c47b9762142f1a42ac490ba258160"}},"4b2d41296399451b863bc1158ad4ea5b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"df4604606a3e43f489e0bd39af12ce40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c6944bb5e5ab4fdc80b90a47ea831f28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9f0c47b9762142f1a42ac490ba258160":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"VXk7kLt7T84C"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","import os\n","os.chdir(\"/content/drive/MyDrive/BERT\")\n","!pip install transformers\n","from transformers import AutoModel, AutoTokenizer\n","import re\n","import pandas as pd\n","import numpy as np\n","import random\n","import torch\n","from torch import nn, optim\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import f1_score, accuracy_score\n","from transformers import get_linear_schedule_with_warmup, get_constant_schedule, AdamW"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g4YHrb8TUn5c"},"source":["# Read data\n","\n","Split train and test set.\n","\n","Encode data usinng tokenizer from pretrained phobert."]},{"cell_type":"code","metadata":{"id":"D8tZpW82UX5b"},"source":["# def read_data(path):\n","#   with open(path) as f:\n","#     data = f.read().splitlines()\n","#   return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zTDI-HkWU3Jr"},"source":["# data = read_data(\"80k_dataset/data.txt\")\n","# label = read_data(\"80k_dataset/label.txt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Vasc5qu3nPm"},"source":["dataset = pd.read_csv(\"dataset_original.csv\")\n","data = dataset[\"data\"].values\n","label = dataset[\"label\"].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JRbYHa0u535j","executionInfo":{"status":"ok","timestamp":1624021745858,"user_tz":-420,"elapsed":27,"user":{"displayName":"Giang Vũ Long","photoUrl":"","userId":"14782662241662995060"}},"outputId":"484006d1-3d48-4438-e074-e677b487e1ab"},"source":["len(data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["135622"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"3Rutcd1vWqdo"},"source":["# def remove_quotes_and_parenthesis(data):\n","#   result = []\n","#   for text in data:\n","#     result.append(re.sub(r\"[\\\"\\']\", \"\", text))\n","#   return result\n","# data = remove_quotes_and_parenthesis(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AX3O9AgYWvG1"},"source":["train_dataset = {\"data\": data[:80000],\"label\": label[:80000]}\n","test_dataset = {\"data\": data[80000:], \"label\": label[80000:]}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m8N_S88KVYKW","executionInfo":{"status":"ok","timestamp":1624021745861,"user_tz":-420,"elapsed":13,"user":{"displayName":"Giang Vũ Long","photoUrl":"","userId":"14782662241662995060"}},"outputId":"43e8ae10-3222-4493-866f-293d77ed7d30"},"source":["print(\"Train data:\\n\")\n","for i in range(5):\n","  print(\"text: \", train_dataset[\"data\"][i], \"\\nlabel\", train_dataset[\"label\"][i])\n","print(\"Test data:\\n\")\n","for i in range(5):\n","  print(\"text: \", test_dataset[\"data\"][i], \"\\nlabel\", test_dataset[\"label\"][i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train data:\n","\n","text:   Ảnh : Vũ_Di Tài_xế Nguyễn_Thế_Vũ kể : Khi lên xe , ngay_lập_tức thanh_niên xăm trổ liền khống_chế tôi , thu hết điện_thoại và giấy_tờ xe . \n","label Pháp luật.txt\n","text:   Dù không ở khách_sạn để tránh tốn_kém nhưng ông Park cũng đề_nghị VFF phải duy_trì thực_đơn ăn_uống như tại khách_sạn cao_cấp , nếu các tuyển_thủ muốn ăn gì thì phải để họ được ăn . \n","label Thể thao.txt\n","text:   Ông Lê Nguyễn_Minh_Quang , Trưởng Ban đường_sắt đô_thị TP HCM cho biết : Chúng_tôi vẫn kiên_trì đeo_bám , kiến_nghị làm_việc cụ_thể . \n","label Xã hội.txt\n","text:   * Trong bối_cảnh quan_hệ Thổ_Nhĩ_Kỳ với phương Tây đang xuống_dốc không phanh , thì sự_cố xảy ra tại cuộc tập_trận chung của Liên_minh quân_sự tại Na_Uy vừa_rồi như là một cú đẩy Ankara lại gần hơn_nữa với các đối_thủ của NATO là Nga và Iran NATO đang đẩy Thổ_Nhĩ_Kỳ ngã vào lòng Nga ? \n","label Thế giới.txt\n","text:   Chúng_tôi xin giới_thiệu một_số điểm du_lịch thú_vị được nhiều người chọn nhất hiện_nay để các gia_đình có_thể dễ_dàng lựa_chọn : Săn ảnh miền núi_rừng phía Bắc_Nếu những_ai yêu thích nhiếp_ảnh thì đây là cơ_hội tuyệt_vời để bạn đặt_chân lên miền rẻo_cao phương Bắc , dù Đông_Bắc hùng_vĩ hay Tây_Bắc hoang_sơ đều mang đến bạn thật nhiều cảm_xúc để sáng_tác nên những bức ảnh đẹp . \n","label Văn hóa.txt\n","Test data:\n","\n","text:   Tuy_nhiên , khi SAOstar liên_hệ với phía Nguyễn_Thị_Loan để làm rõ thông_tin , người đại_diện của cô cho_hay , chân dài gốc Thái_Bình chọn giải_pháp im_lặng , bởi tất_cả vẫn là kế_hoạch . \n","label Giải trí.txt\n","text:   Các bộ_trưởng quốc_phòng ASEAN tham_gia khai_mạc Hội_nghị bộ_trưởng quốc_phòng ASEAN ADMM lần thứ ở Philippines ngày . \n","label Thế giới.txt\n","text:   Động_cơ vẫn chưa tiết_lộ EcoSport cũng trang_bị động_cơ tăng áp EcoBoost . \n","label Xe cộ.txt\n","text:   Từ đây , đường_dây buôn_bán phụ_nữ qua biên_giới Trung_Việt , tới các tỉnh Hà_Nam , An_Huy , Giang_Tây bị phơi_bày . \n","label Pháp luật.txt\n","text:   Cách sử_dụng dầu gạo cũng tương_tự như các loại dầu ăn khác , có_thể ăn trực_tiếp như trộn salad hoặc dùng để nấu . \n","label Đời sống.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":181,"referenced_widgets":["e281dfa3a93c4653b05093d15d465570","56786dfc7cc34c3bb5cd4710f95be7c6","195d00f6be33479185e25d4d31a09347","aee06554a6d54f9587823015e9afb024","913712c43e5b4007a375b920c219df66","86d28ce581e6474e9745d5790cfb7979","5d0512bd76b74b27ab6797d7bc6bbdb4","9ca78c0d2b154ac9b569a0fc1002136e","d3496dc2ecbc432f9759a72f87c672b8","334b8572b7ed466f91924d72754b53c0","0f2daaeb9c4a411aa36ae63e80e283dc","0376b7fa518745b28f84cb2070c6cc04","dfbcb35d184b4eea8f5277fddb33b7ea","359601cc6fb8417d9ef10a407e9cea4b","d76ae51a3b9b468ab3f45d3f6f8857c4","b7bdfb3745cf4c5999a079baf82b202d","5f92153bdb574cc58aec69972c177d0c","836ff1babeea4a79af5ca44b0dcbbed0","a8f044f7ef7c4d328b456de016279cf1","0e34927b3ede40d599526d056dd7b5a0","4b2d41296399451b863bc1158ad4ea5b","df4604606a3e43f489e0bd39af12ce40","c6944bb5e5ab4fdc80b90a47ea831f28","9f0c47b9762142f1a42ac490ba258160"]},"id":"UwxzApC5WmJz","executionInfo":{"status":"ok","timestamp":1624021749440,"user_tz":-420,"elapsed":3588,"user":{"displayName":"Giang Vũ Long","photoUrl":"","userId":"14782662241662995060"}},"outputId":"9e7d9800-92f0-4dd9-c037-21a808e95c03"},"source":["tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n","\n","sequence_length = 128\n","\n","def encode_data(data, tokenizer):\n","  result = []\n","  for text in data:\n","    temp = tokenizer.encode(text)\n","\n","    if(len(temp) < sequence_length):\n","      temp += [1]*(sequence_length-len(temp))\n","    elif len(temp) > sequence_length:\n","      temp = temp[:sequence_length]\n","      temp[-1] = tokenizer.eos_token_id\n","    result.append(temp)\n","  return result"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e281dfa3a93c4653b05093d15d465570","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=557.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3496dc2ecbc432f9759a72f87c672b8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=895321.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f92153bdb574cc58aec69972c177d0c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1135173.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vb_0ErNMX8X3","executionInfo":{"status":"ok","timestamp":1624021778176,"user_tz":-420,"elapsed":28748,"user":{"displayName":"Giang Vũ Long","photoUrl":"","userId":"14782662241662995060"}},"outputId":"8eeb0a7b-36c3-4032-a2b2-662653bf72fe"},"source":["train_dataset[\"data\"] = encode_data(train_dataset[\"data\"], tokenizer)\n","test_dataset[\"data\"] = encode_data(test_dataset[\"data\"], tokenizer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (314 > 256). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"aJ5nTv1gY_8c"},"source":["lbencode = LabelEncoder()\n","lbencode.fit(label)\n","train_dataset[\"label\"] = lbencode.transform(train_dataset[\"label\"])\n","test_dataset[\"label\"] = lbencode.transform(test_dataset[\"label\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n6XCd5S5Yui0"},"source":["# Transform to torch dataset and dataloader"]},{"cell_type":"code","metadata":{"id":"fRl2ZaNKYoz6"},"source":["train_dataset_torch = torch.utils.data.TensorDataset(torch.tensor(train_dataset[\"data\"], dtype=torch.long), torch.tensor(train_dataset[\"label\"], dtype=torch.long))\n","test_dataset_torch = torch.utils.data.TensorDataset(torch.tensor(test_dataset[\"data\"], dtype = torch.long), torch.tensor(test_dataset[\"label\"], dtype  = torch.long))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_G3JzPbBaEeG"},"source":["train_loader = torch.utils.data.DataLoader(train_dataset_torch, batch_size=8, shuffle=False)\n","test_loader = torch.utils.data.DataLoader(test_dataset_torch, batch_size=8, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-63VwF8maq_E"},"source":["# Build fine-tuning model to classify data."]},{"cell_type":"code","metadata":{"id":"QB16ODDDapVz"},"source":["class Model(nn.Module):\n","  def __init__(self, n_classes):\n","    super(Model, self).__init__()\n","    self.phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n","    self.lstm = nn.LSTM(input_size=())\n","    self.drop = nn.Dropout(p=0.3)\n","    self.linear1 = nn.Linear(768, 256)\n","    self.linear2 = nn.Linear(256, n_classes)\n","    self.softmax = nn.Softmax(dim = 1)\n","  def forward(self, inputs):\n","    cls_embedding = self.phobert(inputs)[0][:,0,:]\n","    output = self.drop(cls_embedding)\n","    output = self.linear1(output)\n","    output = torch.nn.functional.relu(output)\n","    output = self.linear2(output)\n","    return self.softmax(output)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vFWz4cqWyu9Z"},"source":["# Declare training, validation and evaluation function"]},{"cell_type":"code","metadata":{"id":"ggQpNRTK0qe5"},"source":["def evaluate(y_pred, y_batch):\n","  with torch.no_grad():\n","    y_pred = y_pred.detach().cpu().numpy()\n","    label = np.argmax(y_pred, axis = 1)\n","    y_batch = y_batch.detach().cpu().numpy()\n","    f1 = f1_score(y_batch, label, average='weighted')\n","    acc = accuracy_score(y_batch, label)\n","  return f1, acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"76fbHDvX1U6m"},"source":["def validation(test_loader, loss, model, device):\n","  f1s = []\n","  accs = []\n","  model.eval()\n","  with torch.no_grad():\n","    y_ = []\n","    y = []\n","    y_pred_ = []\n","    for x_batch, y_batch in test_loader:\n","      x_batch = x_batch.to(device)\n","      y.extend(y_batch.numpy())\n","      y_pred = model(x_batch)\n","      y_pred = y_pred.detach().cpu().numpy()\n","      y_pred_.extend(y_pred)\n","      y_pred = np.argmax(y_pred, axis = 1)\n","      y_.extend(y_pred)\n","    f1 = f1_score(y, y_, average = None)\n","    f1s = f1_score(y, y_, average = 'weighted')\n","    accs = accuracy_score(y, y_)\n","    y_pred_ = torch.tensor(y_pred_, dtype= torch.float).to(device)\n","    y = torch.tensor(y, dtype = torch.long).to(device)\n","    loss_value = loss(y_pred_, y)\n","\n","  return loss_value.item(), f1, f1s, accs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Twgyx1ec1YXK"},"source":["def trainOnEpoch(train_loader, model, optimizer, loss, num_epochs, epoch, device, scheduler, history, log_time = 100):\n","  loss_epoch = 0\n","  acc_epoch = 0\n","  f1_epoch = 0\n","  for i, (x_batch, y_batch) in enumerate(train_loader):\n","    model.train()\n","    x_batch = x_batch.to(device)\n","    y_batch = y_batch.to(device)\n","    optimizer.zero_grad()\n","    y_pred = model(x_batch)\n","    loss_value = loss(y_pred, y_batch)\n","    f1, acc = evaluate(y_pred, y_batch)\n","\n","    loss_value.backward()\n","    #nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1.0)\n","    optimizer.step()\n","    loss_epoch += loss_value.item()\n","    acc_epoch += acc\n","    f1_epoch += f1\n","    scheduler.step()\n","    if (i+1) % log_time == 0 or i + 1 == len(train_loader):\n","      print(\"[TRAIN EPOCH {}] batch {} / {}, loss: {}, acc: {}, f1_avg:{}\".format(epoch+1, i+1, len(train_loader), loss_epoch / (i + 1), acc_epoch / (i+1), f1_epoch / (i + 1)))\n","      history[\"loss_train\"].append(loss_epoch / (i+1))\n","      history[\"acc_train\"].append(acc_epoch / (i+1))\n","      history[\"f1_train\"].append(f1_epoch / (i + 1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"895xtowbgglM"},"source":["# Declare hyperparameters and train model."]},{"cell_type":"code","metadata":{"id":"MWa7fvcY8lm8","colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"status":"error","timestamp":1624030024149,"user_tz":-420,"elapsed":991,"user":{"displayName":"Giang Vũ Long","photoUrl":"","userId":"14782662241662995060"}},"outputId":"35288788-36c4-4578-a3f3-0bd6c255a203"},"source":["EPOCHS = 50\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","CHECKPOINT_PATH = \"checkpoint_model_4/last_model.pth.tar\"\n","CHECKPOINT_BEST_PATH = \"checkpoint_model_4/best_model.path.tar\"\n","\n","history = {\"loss_train\": [], \"acc_train\":[], \"f1_train\":[]}\n","\n","model = Model(11)\n","model.to(DEVICE)\n","loss_function = nn.CrossEntropyLoss()\n","optimizer = AdamW(model.parameters(), lr=1e-5)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=len(train_loader)*(EPOCHS-1))\n","scheduler_frozen = get_constant_schedule(optimizer)\n","start_epoch = 0\n","frozen = True\n","for child in model.phobert.children():\n","  for param in child.parameters():\n","    param.requires_grad = False\n","\n","if os.path.exists(\"history_model_4/f1_valid.txt\"):\n","  with open(\"history_model_4/f1_valid.txt\") as f:\n","    max_score = f.read().splitlines()\n","  start_epoch = len(max_score)\n","  max_score = np.array(max_score).astype(float)\n","  last_score = max_score[-1]\n","  max_score = np.max(max_score)\n","else:\n","  max_score = 0\n","  last_score = 0\n","\n","if os.path.exists(CHECKPOINT_PATH):\n","  checkpoint = torch.load(CHECKPOINT_PATH)\n","  model.load_state_dict(checkpoint[\"model_state_dict\"])\n","  optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n","  scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n","  loss_function.load_state_dict(checkpoint[\"loss_state_dict\"])\n","\n","for epoch in range(start_epoch, EPOCHS, 1):\n","  if epoch > 0 and frozen:\n","    for child in model.phobert.children():\n","      for param in child.parameters():\n","        param.requires_grad = True\n","    del scheduler_frozen\n","    torch.cuda.empty_cache()\n","    frozen = False\n","  print(\"EPOCH \", epoch+1, \"/\", EPOCHS, \":\")\n","\n","  if epoch == 30:\n","    dict_ = optimizer.state_dict()\n","    dict_['param_groups'][0]['initial_lr'] = scheduler.state_dict()['_last_lr']\n","    dict_['param_groups'][0]['lr'] = scheduler.state_dict()['_last_lr']\n","    optimizer.load_state_dict(dict_)\n","    scheduler = get_constant_schedule(optimizer)\n","\n","  if frozen:\n","    trainOnEpoch(train_loader=train_loader, model = model, optimizer = optimizer, loss= loss_function, num_epochs = EPOCHS, epoch = epoch, device = DEVICE, scheduler = scheduler_frozen, history=history)\n","  else:\n","    trainOnEpoch(train_loader=train_loader, model = model, optimizer = optimizer, loss= loss_function, num_epochs = EPOCHS, epoch = epoch,device = DEVICE, scheduler = scheduler, history= history)\n","  losses, f1_classes, f1, acc = validation(test_loader, loss_function, model, DEVICE)\n","  \n","  print(\"EPOCH \", epoch+1, \"/\", EPOCHS, \":\", \" acc: {}, f1_score: {}\".format(acc, f1))\n","\n","  with open('history_model_4/loss.txt', 'a+') as f:\n","    f.write(str(losses) + \"\\n\")\n","  with open('history_model_4/f1_classes.txt', 'a+') as f:\n","    f.write(' '.join(f1_classes.astype(str)) + \"\\n\")\n","  with open(\"history_model_4/loss_train.txt\", \"a+\") as f:\n","    for item in history[\"loss_train\"]:\n","      f.write(str(item) + \"\\n\")\n","  with open(\"history_model_4/acc_train.txt\", \"a+\") as f:\n","    for item in history[\"acc_train\"]:\n","      f.write(str(item) + \"\\n\")\n","  with open(\"history_model_4/f1_train.txt\", \"a+\") as f:\n","    for item in history[\"f1_train\"]:\n","      f.write(str(item) + \"\\n\")\n","  with open(\"history_model_4/acc_valid.txt\", \"a+\") as f:\n","    f.write(str(acc) + \"\\n\")\n","  with open(\"history_model_4/f1_valid.txt\", \"a+\") as f:\n","    f.write(str(f1) + \"\\n\")\n","  dict_ = {\n","        \"model_state_dict\": model.state_dict(),\n","        \"optimizer_state_dict\": optimizer.state_dict(),\n","        \"scheduler_state_dict\": scheduler.state_dict(),\n","        \"loss_state_dict\": loss_function.state_dict(),\n","  }\n","  torch.save(dict_, CHECKPOINT_PATH)\n","  #Save model chechk point\n","  if f1 > max_score:\n","    torch.save(dict_, CHECKPOINT_BEST_PATH)\n","    max_score = f1\n","  elif f1 - last_score < -0.02:\n","    break\n","  last_score = f1\n","  history = {\"loss_train\": [], \"acc_train\":[], \"f1_train\":[]}"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-865ccfecea31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mtrainOnEpoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscheduler_frozen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mtrainOnEpoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-5e055a0ca443>\u001b[0m in \u001b[0;36mtrainOnEpoch\u001b[0;34m(train_loader, model, optimizer, loss, num_epochs, epoch, device, scheduler, history, log_time)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m#nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"n-n3Os-S0zWz"},"source":[""],"execution_count":null,"outputs":[]}]}